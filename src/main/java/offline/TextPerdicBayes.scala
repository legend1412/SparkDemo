package offline

import org.apache.log4j.{Level, Logger}
import org.apache.spark.ml.classification.NaiveBayes
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, IDF, StringIndexer}
import org.apache.spark.sql.SparkSession

object TextPerdicBayes {
  def main(args: Array[String]): Unit = {
    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)

    System.setProperty("HADOOP_USER_NAME", "root")
    val warehouse = "hdfs://master:9000/usr/soft/apache-hive-1.2.2-bin/warehouse"

    val spark = SparkSession.builder()
      .config("spark.sql.warehouse.dir", warehouse)
      .master("local[2]")
      .appName("User Base")
      .enableHiveSupport()
      .getOrCreate()

    val dforgin = spark.sql("select * from badou.news_seg")
    //    dforgin.show()

    /**
     * +--------------------------------+
     * |                        sentence|
     * +--------------------------------+
     * |  无锡 双龙 雷斯特 优惠 元 另...|
     * | 郭晶晶 香港 压轴 婚典 伏明霞...|
     * |  摩托罗拉 吐 槽 再次 抨击 续...|
     * |   四川 女 富商 全国 征婚 上 ...|
     * |   最新 研究 称 近 距 双子星 ...|
     * |   核心 股东 减 持 凶猛 个人 ...|
     * +--------------------------------+
     */
    //    dforgin.show(1,false)
    /**
     * +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
     * |sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
     * +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
     * | 无锡 双龙 雷斯特 优惠 元 另 赠送 礼包 搜狐 汽车 购车 咨询 热线 ： 转 搜狐 汽车 无锡 站 编辑 ： 赏 车 、 购车 、 聊 车 、 玩 车 搜狐 汽车 无锡 车友 群 ： （ 此 群 已 满 ） 搜狐 汽车 无锡 车友 群 ： （ 请 加 此 群 ） 搜狐 汽车 无锡 车友 群 ： （ 此 群 已 满 ） 搜狐 汽车 无锡 车友 群 ： （ 此 群 已 满 ） 搜狐 汽车 无锡 车友 群 ： （ 此 群 已 满 ） 搜狐 汽车 无锡 车友 群 ： （ 此 群 已 满 ） （ 加 群 须知 ： 新人 报道 并 改 网名 ， 格式 为 区 名 车型 网名 ） 无锡 车友 会 ： 责任 编辑 ： 杨 冲 冲 分享##@@##auto|
     * +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
     */
    val df = dforgin.selectExpr("split(sentence,'##@@##')[0] as sentence", "split(sentence,'##@@##')[1] as label")
    //    df.show()

    /**
     * +--------------------------------+--------+
     * |                        sentence|   label|
     * +--------------------------------+--------+
     * |  无锡 双龙 雷斯特 优惠 元 另...|    auto|
     * | 郭晶晶 香港 压轴 婚典 伏明霞...|    yule|
     * |  摩托罗拉 吐 槽 再次 抨击 续...|      it|
     * |   四川 女 富商 全国 征婚 上 ...|business|
     * |   最新 研究 称 近 距 双子星 ...|      it|
     * |   核心 股东 减 持 凶猛 个人 ...|business|
     * +--------------------------------+--------+
     */
    val df1 = df.selectExpr("split(sentence,' ') as sentence", "label")
    //    df1.show()
    /**
     * +----------------------------+--------+
     * |                    sentence|   label|
     * +----------------------------+--------+
     * |[, 无锡, 双龙, 雷斯特, 优...|    auto|
     * |[, 郭晶晶, 香港, 压轴, 婚...|    yule|
     * |[, 摩托罗拉, 吐, 槽, 再次...|      it|
     * | [, 四川, 女, 富商, 全国,...|business|
     * |  [, 最新, 研究, 称, 近, ...|      it|
     * |  [, 核心, 股东, 减, 持, ...|business|
     * +----------------------------+--------+
     */

    val coltf = "feature_tf"
    //setBinary(true) bernoulli 伯努利分布统计出来的单词只表示出现或者没出现，一个单词在文章中出现了10此，这个单词用伯努利表示就是1，没有出现就是0
    //setBinary(false) multinomial 正常词频统计，一个单词出现10次，值为10，这种就是多项式分布
    val hashingtf = new HashingTF()
      .setBinary(false) // 涉及到统计的数据分布式伯努利分布（0,1）true 还是多项式分布（词频分布）false
      //.setBinary(true)
      .setInputCol("sentence")
      .setOutputCol(coltf)
      .setNumFeatures(1 << 18) //2的18次 262144 表示此表大小 对应是文本向量的大小

    val df_tf = hashingtf.transform(df1)
    //df_tf.show()

    /**
     * +----------------------------+--------+--------------------+
     * |                    sentence|   label|          feature_tf|
     * +----------------------------+--------+--------------------+
     * |[, 无锡, 双龙, 雷斯特, 优...|    auto|(262144,[25092,30...|
     * |[, 郭晶晶, 香港, 压轴, 婚...|    yule|(262144,[1147,116...|
     * |[, 摩托罗拉, 吐, 槽, 再次...|      it|(262144,[2715,340...|
     * | [, 四川, 女, 富商, 全国,...|business|(262144,[417,958,...|
     * |  [, 最新, 研究, 称, 近, ...|      it|(262144,[1462,189...|
     * +----------------------------+--------+--------------------+
     */
    val df_tf_feature = df_tf.selectExpr("feature_tf", "label")
    //    df_tf_feature.show(1, false)

    /**
     * sparseVector(向量大小,[index],[value])
     * 多项式 [0,1,0,2,0,0,0,0,3] (9,[1,3,8],[1,2,3])
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |feature_tf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |label|
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |(262144,[25092,30776,32170,37868,41381,46345,47509,52820,53214,54571,56356,59063,68415,85364,101501,111202,115360,119175,122747,137701,145507,146391,152497,154668,156037,158988,161609,170555,172050,174205,181458,183965,184919,195842,197957,198177,205710,210829,226542,236972,238938,241664,242670,243109,243937,249040,249180,250396,254957],
     * [1.0,1.0,1.0,7.0,5.0,1.0,1.0,1.0,1.0,13.0,1.0,1.0,1.0,1.0,8.0,1.0,9.0,1.0,7.0,1.0,1.0,1.0,3.0,5.0,1.0,1.0,2.0,2.0,1.0,2.0,1.0,1.0,8.0,1.0,1.0,1.0,1.0,11.0,6.0,3.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,7.0,1.0])|auto |
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     *
     * 伯努利 [0,1,0,2,0,0,0,0,3] (9,[1,3,8],[1,1,1])
     * +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |feature_tf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |label|
     * +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |(262144,[25092,30776,32170,37868,41381,46345,47509,52820,53214,54571,56356,59063,68415,85364,101501,111202,115360,119175,122747,137701,145507,146391,152497,154668,156037,158988,161609,170555,172050,174205,181458,183965,184919,195842,197957,198177,205710,210829,226542,236972,238938,241664,242670,243109,243937,249040,249180,250396,254957],
     * [1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|auto |
     * +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     */
    val idf = new IDF().setInputCol(coltf)
      .setOutputCol("feature_tfidf")
      .setMinDocFreq(2) //取文档频率>=2

    //idf需要fit，要统计doc-freq map  每个单词出现在多少篇文章中
//    val idfModel = idf.fit(df_tf_feature)
//    val df_tfidf = idfModel.transform(df_tf_feature).selectExpr("feature_tfidf", "label")
    //    df_tfidf.show(1,false)

    /**
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |feature_tfidf                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |label|
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     * |(262144,[25092,30776,32170,37868,41381,46345,47509,52820,53214,54571,56356,59063,68415,85364,101501,111202,115360,119175,122747,137701,145507,146391,152497,154668,156037,158988,161609,170555,172050,174205,181458,183965,184919,195842,197957,198177,205710,210829,226542,236972,238938,241664,242670,243109,243937,249040,249180,250396,254957],
     * [2.2223857314469218,0.7803437255901005,3.5863743350525144,5.351292635036672,12.414360305451064,4.915510282332456,3.399162792964368,2.730708224994794,6.707269751560512,37.70789440327249,3.5717755356313616,2.1054384668379345,1.9887708802654167,0.028927636906179426,11.766622309844497,1.9536795604541466,34.691744894824744,4.670387824299471,5.332944000677553,1.4139649268360188,0.8304681127726692,4.092309973524313,5.254328081877752,6.485564516284695,2.1639749692905075,3.060949911865371,12.39288825558904,5.316775126830336,6.707269751560512,5.3401672063567185,0.0,5.859971891173307,0.0032593196621134475,3.8546383216471938,0.377548846037815,1.9365851270948466,3.0522918491222564,2.9120254360154387,10.508656163755504,1.0052647981006768,2.8714081070979294,4.340146137428895,2.788127545037448,2.08229693827624,7.143551071262723,4.438586210242147,0.0,21.80173910599634,1.0431525332967415])|auto |
     * +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
     */
    //Column label must be of type numeric but was actually of type string
    val stringIndex = new StringIndexer()
      .setInputCol("label")
      .setOutputCol("indexed")
      .setHandleInvalid("error")
    //收集label：auto->index(double)
    //val df_tfidf_lab = stringIndex.fit(df_tfidf).transform(df_tfidf)
    val df_tfidf_lab = stringIndex.fit(df_tf).transform(df_tf)
    //    df_tfidf_lab.show()
    /**
     * +--------------------+--------+-------+
     * |          feature_tf|   label|indexed|
     * +--------------------+--------+-------+
     * |(262144,[25092,30...|    auto|    0.0|
     * |(262144,[1147,116...|    yule|    4.0|
     * |(262144,[2715,340...|      it|    1.0|
     * |(262144,[417,958,...|business|    2.0|
     * |(262144,[1462,189...|      it|    1.0|
     * +--------------------+--------+-------+
     */

    val Array(train, test) = df_tfidf_lab.randomSplit(Array(0.8, 0.2))

    //对bayes模型进行实例化，定义参数
    val nb = new NaiveBayes()
      .setModelType("multinomial")
    //  .setModelType("bernoulli")
      .setSmoothing(1)
//      .setFeaturesCol("feature_tfidf")
      .setFeaturesCol("feature_tf")
      .setLabelCol("indexed")
      .setPredictionCol("pre_label")
      .setProbabilityCol("prob")
      .setRawPredictionCol("rawPred")

    //模型训练
    val nbModel = nb.fit(train)
    //模型预测
    val pred = nbModel.transform(test)

    /**
     * param for metric name in evaluation (supports `"f1"` (default), `"weightedPrecision"`,
     * `"weightedRecall"`, `"accuracy"`)
     *
     * @group param
     */
    val eval = new MulticlassClassificationEvaluator()
      .setLabelCol("indexed")
      .setPredictionCol("pre_label")
      .setMetricName("accuracy")

    val accuracy = eval.evaluate(pred)
    println("Test accuracy:" + accuracy)
  }
}
