package CF

import breeze.numerics.{pow, sqrt}
import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

object UserBase {
  def main(args: Array[String]): Unit = {
    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)

    System.setProperty("HADOOP_USER_NAME", "root")
    val warehouse = "hdfs://master:9000/usr/soft/apache-hive-1.2.2-bin/warehouse"

    val spark = SparkSession.builder()
      .config("spark.sql.warehouse.dir", warehouse)
      .master("local[2]")
      .appName("User Base")
      .enableHiveSupport()
      .getOrCreate()

    val df = spark.sql("select user_id,item_id,rating from badou.udata")
    /**
     * +-------+-------+------+
     * |user_id|item_id|rating|
     * +-------+-------+------+
     * |    196|    242|     3|
     * |    186|    302|     3|
     * |     22|    377|     1|
     * |    244|     51|     2|
     * |    166|    346|     1|
     * +-------+-------+------+
     */
    //1.计算相似用户  相似度度量 cosine = a*b/(|a|*|b|) a和b的点乘
    //选取的用户和相似用户都是在user_id中

    //每一个用户的分母
    //第一种方法，使用sql
    // 选择一个用户
    val df1 = df.filter("user_id='196'")
    /**
     * +-------+-------+------+
     * |user_id|item_id|rating|
     * +-------+-------+------+
     * |    196|    242|     3|
     * |    196|    393|     4|
     * |    196|      8|     5|
     * |    196|    428|     4|
     * |    196|   1118|     4|
     * +-------+-------+------+
     */
    // 求平方
    val df2 = df.selectExpr("*", "pow(cast(rating as double),2) as pow_rating")
    /**
     * +-------+-------+------+----------+
     * |user_id|item_id|rating|pow_rating|
     * +-------+-------+------+----------+
     * |    196|    242|     3|       9.0|
     * |    186|    302|     3|       9.0|
     * |     22|    377|     1|       1.0|
     * |    244|     51|     2|       4.0|
     * |    194|    274|     2|       4.0|
     * +-------+-------+------+----------+
     */
    // 求平方和
    val df3 = df2.groupBy("user_id").agg(sum("pow_rating").as("sum_pow_rating"))
    /**
     * +-------+--------------+
     * |user_id|sum_pow_rating|
     * +-------+--------------+
     * |    467|         638.0|
     * |    675|         528.0|
     * |    296|        2770.0|
     * |    718|         574.0|
     * |    574|         634.0|
     * +-------+--------------+
     */
    // 求平方根
    val userScoreSum = df3.selectExpr("*", "sqrt(sum_pow_rating) as sqrt_rating")

    /**
     * +-------+--------------+------------------+
     * |user_id|sum_pow_rating|       sqrt_rating|
     * +-------+--------------+------------------+
     * |    467|         638.0| 25.25866188063018|
     * |    675|         528.0|22.978250586152114|
     * |    296|        2770.0|52.630789467763066|
     * |    691|         611.0| 24.71841418861655|
     * |     51|         324.0|              18.0|
     * +-------+--------------+------------------+
     */
    //另外一个方法 rdd,这种方式偏底层，结果跟userScoreSum一样
    import spark.implicits._
    val userScoreSumRdd = df.rdd.map(x => (x(0).toString, x(2).toString))
      .groupByKey()
      .mapValues(x => sqrt(x.toArray.map(rating => pow(rating.toDouble, 2)).sum))
      .toDF("user_id", "sqrt_rating")

    // 1.1 倒排表 item->users

    val df_v = df.selectExpr("user_id as user_v", "item_id", "rating as rating_v")
    /**
     * +------+-------+--------+
     * |user_v|item_id|rating_v|
     * +------+-------+--------+
     * |   196|    242|       3|
     * |   186|    302|       3|
     * |    22|    377|       1|
     * |   244|     51|       2|
     * |   166|    346|       1|
     * +------+-------+--------+
     */
    val df_decare = df.join(df_v, "item_id").filter("cast(user_id as long)<>cast(user_v as long)")

    /**
     * +-------+-------+------+------+--------+
     * |item_id|user_id|rating|user_v|rating_v|
     * +-------+-------+------+------+--------+
     * |    242|    196|     3|   721|       3|
     * |    242|    196|     3|   720|       4|
     * |    242|    196|     3|   500|       3|
     * |    242|    196|     3|   845|       4|
     * |    242|    196|     3|   305|       5|
     * +-------+-------+------+------+--------+
     */
    //计算两个用户在同一个item下的评分的乘积，就是cosine公式的分子中的一部分
    val df_product = df_decare.selectExpr("user_id", "user_v", "cast(rating as double)*cast(rating_v as double) as prod")

    /**
     * +-------+------+----+
     * |user_id|user_v|prod|
     * +-------+------+----+
     * |    196|   721| 9.0|
     * |    196|   720|12.0|
     * |    196|   500| 9.0|
     * |    196|   845|12.0|
     * |    196|   305|15.0|
     * +-------+------+----+
     */

    //相同的两个用户会有在不同item上的打分,其实就是两个用户在item上的交集
    // df_product.filter("user_id='196' and user_v='721'").show()

    /**
     * +-------+------+----+
     * |user_id|user_v|prod|
     * +-------+------+----+
     * |    196|   721| 9.0|
     * |    196|   721|20.0|
     * |    196|   721|10.0|
     * |    196|   721|12.0|
     * |    196|   721|16.0|
     * +-------+------+----+
     */
    //求和，计算完整的分子部分
    val df_sim_group = df_product.groupBy("user_id", "user_v").agg(sum("prod").as("rating_dot"))


    /**
     * +-------+------+----------+
     * |user_id|user_v|rating_dot|
     * +-------+------+----------+
     * |    196|   617|      24.0|
     * |    196|   123|      71.0|
     * |    166|   206|     104.0|
     * |    298|   465|     523.0|
     * |    305|   807|     843.0|
     * +-------+------+----------+
     */

    //user_v的分母
    val userScoreSum_v = userScoreSum.selectExpr("user_id as user_v", "sqrt_rating as sqrt_rating_v")
    //带入user_id的分母和user_v的分母
    val df_sim = df_sim_group.join(userScoreSum, "user_id").join(userScoreSum_v, "user_v")

    /**
     * +------+-------+----------+--------------+------------------+------------------+
     * |user_v|user_id|rating_dot|sum_pow_rating|       sqrt_rating|     sqrt_rating_v|
     * +------+-------+----------+--------------+------------------+------------------+
     * |   617|    196|      24.0|         549.0|23.430749027719962| 30.54504869860253|
     * |   123|    196|      71.0|         549.0|23.430749027719962|29.427877939124322|
     * |   206|    166|     104.0|         291.0| 17.05872210923198|20.904544960366874|
     * |   465|    298|     523.0|        2148.0| 46.34652090502587|31.575306807693888|
     * |   807|    305|     843.0|        2839.0| 53.28226721902888| 56.83308895353129|
     * +------+-------+----------+--------------+------------------+------------------+
     */
    //进行cosine计算
    val df_cosine = df_sim.selectExpr("user_id", "user_v", "rating_dot/(sqrt_rating*sqrt_rating_v) as cosine_sim")
    //    df_cosine.show()

    /**
     * +-------+------+--------------------+
     * |user_id|user_v|          cosine_sim|
     * +-------+------+--------------------+
     * |    196|   617|0.033533914107330615|
     * |    196|   123| 0.10297059695164824|
     * |    166|   206| 0.29163935315828643|
     * |    298|   465| 0.35738553543065843|
     * |    305|   807| 0.27838358105878475|
     * +-------+------+--------------------+
     */
    //2.获取相似用户的物品集合
    //2.1 取前n个相似用户
    val df_nsim = df_cosine.rdd.map(x => (x(0).toString, (x(1).toString, x(2).toString)))
      .groupByKey()
      .mapValues(_.toArray.sortWith((x, y) => x._2.toDouble > y._2.toDouble).slice(0, 5))
      .flatMapValues(x => x)
      .toDF("user_id", "user_v_sim")

    //    df_nsim.show()

    /**
     * +-------+--------------------+
     * |user_id|          user_v_sim|
     * +-------+--------------------+
     * |    385|[308, 0.499661174...|
     * |    385|[833, 0.494909936...|
     * |    385|[561, 0.489420469...|
     * |    385|[747, 0.489143717...|
     * |    385|[269, 0.486101128...|
     * +-------+--------------------+
     */
    val df_nsim_r = df_nsim.selectExpr("user_id", "user_v_sim._1 as user_v", "user_v_sim._2 as sim")
    //    df_nsim_r.show()

    /**
     * +-------+------+-------------------+
     * |user_id|user_v|                sim|
     * +-------+------+-------------------+
     * |    385|   308|0.49966117411717703|
     * |    385|   833|0.49490993620255647|
     * |    385|   561| 0.4894204693024517|
     * |    385|   747|0.48914371760013464|
     * |    385|   269| 0.4861011288308306|
     * +-------+------+-------------------+
     */
    //2.2  获取用户的物品集合进行过滤
    //获取user_id物品集合（同样能把user_v的物品集合取到） df user_id,item_id rating
    val df_user_item = df.rdd.map(x => (x(0).toString, x(1).toString + "_" + x(2).toString))
      .groupByKey().mapValues(_.toArray).toDF("user_id", "item_rating_arr")
    //    df_user_item.show()

    /**
     * +-------+--------------------+
     * |user_id|     item_rating_arr|
     * +-------+--------------------+
     * |    273|[328_3, 345_3, 31...|
     * |    528|[485_2, 239_5, 58...|
     * |    584|[114_4, 258_4, 17...|
     * |    736|[181_2, 296_4, 53...|
     * +-------+--------------------+
     */
    //列需要看全，不带省略号
    //    df_user_item.show(1, false)
    /**
     * +------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
     * |user_v|item_rating_arr_v                                                                                                                                         |
     * +------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
     * |273   |[328_3, 345_3, 311_4, 902_5, 900_3, 690_4, 319_4, 321_4, 303_4, 305_4, 315_4, 316_4, 340_3, 272_4, 347_4, 313_3, 304_3, 307_2, 286_3, 268_5, 896_4, 338_3]|
     * +------+----------------------------------------------------------------------------------------------------------------------------------------------------------+
     */
    //标识user_v对于user_id的列名区别
    val df_user_item_v = df_user_item.selectExpr("user_id as user_v", "item_rating_arr as item_rating_arr_v")

    //    df_user_item_v.show()
    /**
     * +------+--------------------+
     * |user_v|   item_rating_arr_v|
     * +------+--------------------+
     * |   273|[328_3, 345_3, 31...|
     * |   528|[485_2, 239_5, 58...|
     * |   584|[114_4, 258_4, 17...|
     * |   736|[181_2, 296_4, 53...|
     * |   456|[175_3, 715_3, 94...|
     * +------+--------------------+
     */

    //将user_id的物品集合关联进来，同时关联相似用户user_v的物品集合

    val df_get_item = df_nsim_r.join(df_user_item, "user_id").join(df_user_item_v, "user_v")
    df_get_item.show()

    /**
     * +------+-------+-------------------+--------------------+--------------------+
     * |user_v|user_id|                sim|     item_rating_arr|   item_rating_arr_v|
     * +------+-------+-------------------+--------------------+--------------------+
     * |   296|     71|0.33828954632615976|[89_5, 134_3, 346...|[705_5, 508_5, 20...|
     * |   296|    753| 0.3968472894511972|[673_1, 79_4, 898...|[705_5, 508_5, 20...|
     * |   296|    376|0.32635213497817583|[237_3, 269_5, 28...|[705_5, 508_5, 20...|
     * |   296|    360| 0.4425631904462532|[334_4, 116_3, 23...|[705_5, 508_5, 20...|
     * |   296|    392| 0.3704196358220336|[178_5, 333_4, 30...|[705_5, 508_5, 20...|
     * +------+-------+-------------------+--------------------+--------------------+
     */

  }
}
